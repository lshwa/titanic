# 모델 학습 시 고려사항 가이드
모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하고 있지 못한다면 결코 의미있지 않습니다.  
코드를 짜는 시간보다 고민하는 데에 더 많은 시간을 할애하셨으면 합니다. 또 결과를 통해 증명하기보다 본인의 논리를 믿고 따르는 습관을 들이면 좋겠습니다. 예상과 다르다면 다시 학습해가면 됩니다.
모든 부분에 힘을 주실 필요가 없습니다.  
--------
모델을 학습할 때는 다양한 요소를 고려해야 합니다. 이는 데이터의 전처리부터 모델의 선택과 평가에 이르기까지 여러 단계에 걸쳐 영향을 미칩니다. 아래는 주요한 요소들을 설명합니다.
1. 결측치 처리
> 🧞‍♀️ 시각화 등으로 결측치를 확인해주세요. 각 열의 결측치를 대체한 방법과 왜 그 방법을 사용했는지에 관하여 논리적으로 서술해주세요.

> 해결방법 :
결측치와 survived랑 상관이 있는지를 확인하여 결측치 처리 결정.
Embarked 컬럼은 너무 경미한 결측치이기에 최빈값으로 대체하기로 했다. 
> 결측치 2개를 Embarked 컬럼의 최빈값인 S로 대체하기로 결정함. 
Cabin 컬럼은 결측치가 너무 많고, Pclass 컬럼과 상관관계를 분석했을 때, Pclass가 1이 2,3 일때보다 더 많이 기록되어있음을 확인하여 편향적인 컬럼이라고 생각하여 drop하기로 결정함.
age와 pclass간 상관관계가 높음을 시각화로 확인하였고, age의 결측치가 3등석에 치우쳐서 분포되어 있었기 때문에 pclass별 age의 median을 age의 결측치를 채워넣음. 

- 1번 과정 이후 컬럼 변경사항 
'PassengerId', 'Name', 'Ticket' 은 survived와의 상관관계가 없는 의미없는 자료라고 생각하여 drop함. 

2. 데이터 인코딩
범주형 변수는 모델이 이해할 수 있는 숫자 형태로 변환해야 합니다. 대표적인 방법으로는 Label Encoding(위계가 있는 경우)과 One-Hot Encoding(순서가 없는 경우)이 있습니다. 타겟 인코딩은 범주형 피처를 타겟 변수의 평균이나 비율로 인코딩하는 방법입니다. 타겟 변수가 특정 값일 확률을 사용하기도 합니다.
> 🧞‍♀️ 범주형 변수에 대해서 인코딩을 수행하셨다면 어떤 칼럼에 대해, 어떤 인코딩 방법을 사용하였는지 논리적으로 설명해주세요. (이때, 고려했던 인코딩 방법과 선택하지 않은 이유를 함께 제시해주세요.)

> 해결방법:
Sex 컬럼에 male은 0, female은 1로 설정했고, Label Encoding을 사용했는데, 그 이유는 사실 위계질서가 없는 변수이기에 두 개중에 무엇을 사용해도 상관은 없다고 생각했지만, Embarked는 세 개의 범주에 위계가 없기에 One-Hot Encoding을 사용했어서 Sex 컬럼에는 Label Encoding을 적용해보고 싶어서, 두 개의 인코딩 방법을 각각 적용하였다. Embarked는 C,S,Q 에 대해서 각각에 값이 있을 때는 1(True), 없을 때는 0(False)를 반환하도록 설정하였다.

- 2번 과정 이후 데이터셋의 변화
Embarked 같은 경우는 따로 데이터 인코딩을 진행했기에 컬럼을 제거하였다. 


3. 데이터 스케일링
> 🧞‍♀️ 해당 데이터의 정규화 필요성에 대하여 논의해주세요. 해당 분포를 모델링에 적합한 형태로 변환하기 위해 사용한 스케일링 방식에 대해 설명해주세요.
> (ex. MinMax 스케일링은 이상치에 관하여 민감하므로, 그렇지 않은 ~ 방법을 사용했습니다.)

> 해결방법:
데이터 스케일링하기전에 이상치 값들에 따라 값의 변화가 크게 있을것이라고 생각하여 '5'번 과정을 먼저 진행하고 왔다. 
PClass, Embarked, Family에 관한 부분은 어느정도 값이 범주화가 뚜렷하게 있기에 잘 정리되어있다고 판단해서 Age를 기준으로 이미 이상치도 제거했기에 Age를 대상으로 진행하였다. 
Min-Max 방법을 사용하기에는 1부터 80이라는 범위가 넓다고 생각하여 이상치에 덜 민감하고, 특성간의 비교가 용이한 경사하강법 기반을 모델로 한 표준화를 진행하였다. 이때 평균은 0에 매우 가깝고 표준편차도 1에 매우 가까운 결과값을 도출함으로써 과정이 잘 진행됐음을 확인하였다. 

4. 데이터 왜도
왜도(skewness) 처리: 데이터가 비대칭적으로 분포되어 있을 때 로그 변환, 박스-콕스(Box-Cox) 변환 등을 사용해 왜도를 줄일 수 있습니다. 왜도가 크면 모델의 성능이 저하될 수 있습니다.
> 🧞‍♀️ 어떤 경우에 어떤 왜도 처리를 하는지 공부해보세요. 해당 데이터의 분포를 나타내는 시각화를 진행하고, 왜도를 수치로 표현해보세요.
타이타닉 데이터셋의 각 수치형 컬럼에는 왜도 처리가 필요한가요? 왜 그렇게 판단했나요?

> 해결방법:
Age에 관한 변수에 대해서 스케일링을 하고 난 이후에 데이터 왜도의 수치를 확인해보았다. 'Age Skewness: 0.5783834934172787' 의 결과를 확인할 수 있었고, 이는 절대 크지 않은 약간 우측의 궤도라고 생각하였고 0에 굉장히 가깝기에 모델링 하기에 적합한 수준이라고 생각하여 따로 왜도를 줄이는 방법을 쓰지 않고 넘어가기로 결정하였다. 

5. 이상치(Outliers)
이상치 처리: 이상치는 모델에 부정적인 영향을 줄 수 있기 때문에 이를 식별하고 처리하는 것이 중요합니다. 이상치를 제거하거나, 다른 값으로 대체(예: 중앙값)하는 방법이 있습니다. 이상치가 반드시 잘못된 것은 아니므로 주의해야 합니다.
> 🧞‍♀️ 이상치를 처리하였나요? 어떤 기준으로 이상치를 판단하였나요?

> 해결방법:
현재 내 데이터셋에 있는 컬럼은 Survived  Pclass  Sex  Age  Family  Embarked_C  Embarked_Q  Embarked_S 이렇게 되어있다. 불필요한 값들이라고 생각한 부분은 삭제했고, Family 라는 컬럼은 따로 SibSp, Parch의 값을 합한 컬럼으로 새로 만들었다. 두 개의 컬럼이 단순히 가족이 있을 때와 없을 때의 경우로 봐도 무방하다라고 생가했기에 현재 컬럼처럼 수정했던 것이고, 그 이후에는 Age에 관하여 이상치를 탐색하였다. 
Age에 대한 IQR 기법을 활용하여 계산한 결과, 나이에 대한 부분은 현실적으로 최댓값이 80으로 큰 이상치는 없다고 판단하였다. 하지만, 최솟값이 0으로 되어있는 것을 보아 나이 기입에 문제가 있다고 보아 값이 0은 정상 범위에 포함하기에 애매하기에 이를 평균값으로 대체하는 방법을 활용하였다. 

6. 피처 선택 및 생성
피처 선택(Feature Selection): 모델 성능을 개선하거나 과적합을 방지하기 위해 불필요한 피처를 제거합니다. 이를 위해 통계적 방법(예: p-value), 모델 기반 방법(예: L1 정규화), 또는 피처 중요도를 활용합니다.
피처 생성(Feature Engineering): 모델 성능을 높이기 위해 새로운 피처를 생성할 수 있습니다. 예를 들어, 두 피처를 곱하거나 나누어 새로운 피처를 만들 수 있습니다.
> 🧞‍♀️ 새로 만든 피쳐가 있다면 자랑해주세요.
> 🧞‍♀️ 다중공선성이 있다고 판단되는 지표가 있었나요? 왜 그렇게 생각하셨으며, 어떻게 처리하셨나요?

> 해결방법:
앞서 간단히 설명했지만 두 피처를 결합한 Family라는 피처를 생성했다. SibSp와 Parch 가 보여주는 것은 가족의 유무라고 판단하였기에 가족이 몇명 있는지에 대한 정보를 받기 위해서 가져왔다. 

7. 데이터 분할
훈련/검증/테스트 데이터 분할: 데이터셋을 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가합니다. 일반적으로 70-80%를 훈련 데이터로 사용하고, 나머지를 검증과 테스트 데이터로 사용합니다.
> 🧞‍♀️ 데이터 분할 방법 중 K-Fold Cross-Validation과 Stratified K-fold Cross Validation에 대해 공부해보세요. 최종적으로 어떤 방법을 사용했는지, 왜 사용했는지에 대해 서술해주세요.

> 해결방법:
Logistic Regression Cross-Validation Scores: [0.62011173 0.66292135 0.73595506 0.75280899 0.69662921]
Mean Logistic Regression Cross-Validation Score: 0.6936852677170295
Random Forest Cross-Validation Scores: [0.62011173 0.65168539 0.65168539 0.70224719 0.66292135]
Mean Random Forest Cross-Validation Score: 0.6577302115372544
Gradient Boosting Cross-Validation Scores: [0.63128492 0.71910112 0.73595506 0.7752809  0.73595506]
Mean Gradient Boosting Cross-Validation Score: 0.7195154102065155
이런 결과를 통해 그라디언트 부스팅이라는 모델을 사용해보기로함. 


8. 모델 선택
모델 유형 선택: 데이터의 특성에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 선형 데이터에는 선형 회귀, 비선형 데이터에는 트리 기반 모델 등이 효과적일 수 있습니다.
> 🧞‍♀️ 해당 데이터가 예측하고자 하는 값이 어떤 유형인지에 관련하여 모델 선정의 논리성을 증명해주세요. 또한, 차안으로 선택할 수 있는 모델이 있다면 추천해주세요.
+ 하이퍼파라미터 튜닝: 각 모델의 하이퍼파라미터를 최적화하여 성능을 극대화할 수 있습니다. 그리드 서치(Grid Search)나 랜덤 서치(Random Search) 등의 방법이 도모됩니다.
9. 모델 평가
평가 지표 선택: 회귀 문제에서는 MSE, MAE, R², 분류 문제에서는 정확도, 정밀도, 재현율, F1-score 등을 사용하여 모델 성능을 평가합니다.
교차 검증(Cross-Validation): 데이터를 여러 번 분할하여 모델을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 잘 평가할 수 있습니다.
평가 지표의 종류에 대해 공부해보세요.
10. 과적합 방지
모델의 과적합을 방지하기 위한 여러 방법들이 있습니다.  
- 정규화(Regularization): L1, L2 정규화를 통해 모델의 복잡도를 조절하여 과적합을 방지합니다.  
- 드롭아웃(Dropout): 신경망에서 드롭아웃을 사용하여 과적합을 방지할 수 있습니다.  
- 얼리 스탑핑(Early Stopping): 검증 데이터의 성능이 더 이상 개선되지 않으면 훈련을 조기에 중지합니다.  
> 🧞‍♀️ 과적합 방지를 위해 도입한 방법이 있나요? 그 방법의 원리와 장점은 무엇인가요?
---
*출처: 4기 교육팀장님*

